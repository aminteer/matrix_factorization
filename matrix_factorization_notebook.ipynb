{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine \n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pytest import approx\n",
    "import unittest\n",
    "from collections import namedtuple\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load movie data and set up functions to predict ratings with NMF algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matrix_recommender_system():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n",
    "        self.Mr=self.rating_matrix()\n",
    "        self.Mm=None \n",
    "        self.sim=np.zeros((len(self.allmovies),len(self.allmovies)))\n",
    "    \n",
    "    def setUp(self):\n",
    "\n",
    "        # Creating Sample test data\n",
    "        MV_users = pd.read_csv('data/users.csv')\n",
    "        MV_movies = pd.read_csv('data/movies.csv')\n",
    "        train = pd.read_csv('data/train.csv')\n",
    "        test = pd.read_csv('data/test.csv')\n",
    "        \n",
    "        Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "        self.data = Data(MV_users, MV_movies, train, test)\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        self.sample_train = train[:30000]\n",
    "        self.sample_test = test[:30000]\n",
    "\n",
    "\n",
    "        self.sample_MV_users = MV_users[(MV_users.uID.isin(self.sample_train.uID)) | (MV_users.uID.isin(self.sample_test.uID))]\n",
    "        self.sample_MV_movies = MV_movies[(MV_movies.mID.isin(self.sample_train.mID)) | (MV_movies.mID.isin(self.sample_test.mID))]\n",
    "\n",
    "\n",
    "        self.sample_data = Data(self.sample_MV_users, self.sample_MV_movies, self.sample_train, self.sample_test)\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(self.data.train.rating)\n",
    "        \n",
    "        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "    \n",
    "    def predict_from_sim(self,uid,mid):\n",
    "        \"\"\"\n",
    "        Predict a user rating on a movie given userID and movieID\n",
    "        \"\"\"\n",
    "        # Predict user rating as follows:\n",
    "        # 1. Get entry of user id in rating matrix\n",
    "        # 2. Get entry of movie id in sim matrix\n",
    "        # 3. Employ 1 and 2 to predict user rating of the movie\n",
    "        # your code here\n",
    "        usr_idx = self.uid2idx[uid]\n",
    "        user_ratings = self.Mr[usr_idx]\n",
    "        movie_idx = self.mid2idx[mid]\n",
    "        sim_movie = self.sim[movie_idx]\n",
    "        #need to divide by count of valid ratings to minimize bias\n",
    "        pred = np.dot(user_ratings, sim_movie) / np.dot(user_ratings != 0, sim_movie)\n",
    "        return pred\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        test_preds = []\n",
    "        for i in range(len(self.data.test)):\n",
    "            test_preds.append(self.predict_from_sim(self.data.test.uID[i], self.data.test.mID[i]))\n",
    "        return np.array(test_preds)\n",
    "    \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt=np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())\n",
    "    \n",
    "    def calc_matrixfactor(self):    \n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using matrix factorization with sklearn's NMF\n",
    "        Returns a matrix of size (#all movies, #all movies)\n",
    "        \"\"\"\n",
    "        # Return a sim matrix by calculating item-item similarity for all pairs of items using matrix factorization\n",
    "        \n",
    "        # get movie ratings array\n",
    "        movie_ratings_matrix = self.Mr\n",
    "        # replace Nan with zerios\n",
    "        ratings_imputed = np.nan_to_num(movie_ratings_matrix)   \n",
    "        \n",
    "        # # Replace zeros with NaN for imputation\n",
    "        # ratings = np.where(movie_ratings_matrix == 0, np.nan, movie_ratings_matrix)\n",
    "        # # impute missing values with the mean\n",
    "        # imputer = SimpleImputer(strategy='mean')\n",
    "        # ratings_imputed = imputer.fit_transform(ratings)\n",
    "\n",
    "        # Create an NMF model with 2 components and random initialization\n",
    "        nmf_model = NMF(n_components=2, init='random', random_state=0)\n",
    "\n",
    "        # Factorize the imputed matrix\n",
    "        W = nmf_model.fit_transform(ratings_imputed)  # User features\n",
    "        H = nmf_model.components_                     # Movie features\n",
    "\n",
    "        # Predict ratings\n",
    "        predicted_ratings = np.dot(W, H)\n",
    "        \n",
    "        self.sim = predicted_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model and calculate RSME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "#data_list = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up sample data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "sample_train = train[:30000]\n",
    "sample_test = test[:30000]\n",
    "\n",
    "\n",
    "sample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\n",
    "sample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\n",
    "\n",
    "\n",
    "sample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create estimates using non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/6qq01srd4dx12xk1x9v713jr0000gn/T/ipykernel_3249/532003302.py:59: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pred = np.dot(user_ratings, sim_movie) / np.dot(user_ratings != 0, sim_movie)\n"
     ]
    }
   ],
   "source": [
    "nmf = matrix_recommender_system(sample_data)\n",
    "#nmf.setUp()\n",
    "nmf.calc_matrixfactor()\n",
    "pred = nmf.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.203834519419552\n"
     ]
    }
   ],
   "source": [
    "rsme = nmf.rmse(pred)\n",
    "\n",
    "print(\"RMSE:\", rsme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Discussion\n",
    "RSME is higher than other methods used in Week 3.  Likely causes for this are sparse datasets with many missing values.  Most people have not seen a high propoportion of all movies ever made, so a sparse dataset is expected.  NMF does not work well with sparsity due to less information available for NMF to learn the underlying structure effectively.  \n",
    "\n",
    "NMF might also overfit to observed values, leading to some bias.  It is also sensitive to initialization values which with sparse data can magnify this impact due to lack of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can be done to improve results?\n",
    "\n",
    "To address the sparsity of data, some imputation assumptions can be made to the data.  Filling missing values with averages or assuming a median value could improve the resulting predictions.  Limiting the data used to movies and users with more complete ratings data may also help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
